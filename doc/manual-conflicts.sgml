<chapter id="conflicts" xreflabel="Multi-master conflicts">
 <title>Multi-master conflicts</title>

 <indexterm>
  <primary>Conflicts</primary>
 </indexterm>

 <para>
  In multi-master use of &bdr; writes to the same or related table(s) from multiple
  different nodes can result in data conflicts.
 </para>

 <para>
  Some clustering systems use distributed lock mechanisms to prevent
  concurrent access to data. These can perform reasonably when servers are
  very close but cannot support geographically distributed applications as
  very low latency is critical for acceptable performance.
 </para>

 <para>
  Distributed locking is essentially a pessimistic approach, whereas BDR
  advocates an optimistic approach: avoid conflicts where possible but allow
  some types of conflict to occur and and resolve them when they arise.
 </para>

 <sect1 id="conflicts-how" xreflabel="How conflicts happen">
  <title>How conflicts happen</title>

  <para>
   Inter-node conflicts arise as a result of sequences of events that could not
   happen if all the involved transactions happened concurrently on the same
   node. Because the nodes only exchange changes after transactions commit, each
   transaction is individually valid on the node it committed on but would not
   be valid if run on another node that has done other work in the mean time.
   Since &bdr; apply essentially replays the transaction on the other nodes, the
   replay operation can fail if there is a conflict between a transaction being
   applied and a transaction that was committed on the receiving node.
  </para>

  <para>
   The reason most conflicts can't happen when all transactions run on a single
   node is that PostgreSQL has inter-transaction communication mechanisms
   to prevent it - <literal>UNIQUE</literal> indexes,
   <literal>SEQUENCE</literal>s, row and relation locking,
   <literal>SERIALIZABLE</literal> dependency tracking, etc. All of these
   mechanisms are ways to communicate between transactions to prevent
   undesirable concurrency issues.
  </para>

  <para>
   &bdr; does not have a distributed transaction manager or lock manager.
   That's part of why it performs well with latency and network partitions. As
   a result, so <emphasis>transactions on different nodes execute entirely in
   isolation from each other</emphasis>. Despite the usual perception that
   "more isolation is good" you actually need to reduce isolation to prevent
   conflicts.
  </para>

 </sect1>

 <sect1 id="conflicts-types" xreflabel="Types of conflict">
  <title>Types of conflict</title>

  <sect2 id="conflicts-key" xreflabel="PRIMARY KEY or UNIQUE row conflicts">
   <title><literal>PRIMARY KEY</literal> or <literal>UNIQUE</literal> conflicts</title>

   <para>
    The most common conflicts are row conflicts where two operations affect a
    row with the same key in ways they could not do on a single node. &bdr; can
    detect most of those and apply last-update-wins conflict handling or invoke
    a user-defined conflict handler.
   </para>

   <para>
    Row conflicts include:
    <itemizedlist>
     <listitem><simpara><literal>INSERT</literal> vs <literal>INSERT</literal></simpara></listitem>
     <listitem><simpara><literal>INSERT</literal> vs <literal>UPDATE</literal></simpara></listitem>
     <listitem><simpara><literal>UPDATE</literal> vs <literal>DELETE</literal></simpara></listitem>
     <listitem><simpara><literal>INSERT</literal> vs <literal>DELETE</literal></simpara></listitem>
     <listitem><simpara><literal>DELETE</literal> vs <literal>DELETE</literal></simpara></listitem>
    </itemizedlist>
   </para>

   <sect3 id="conflicts-insert-insert"
          xreflabel="INSERT/INSERT conflicts">

    <title>INSERT/INSERT conflicts</title>

    <para>
     The most common conflict, <literal>INSERT</literal> vs
     <literal>INSERT</literal>, arises where <literal>INSERT</literal>s on two
     different nodes create a tuple with the same <literal>PRIMARY
     KEY</literal> values (or the same values for a single
     <literal>UNIQUE</literal> constraint if no <literal>PRIMARY KEY</literal>
     exists).  &bdr; handles this by retaining the most recently inserted tuple
     of the two according to the originating host's timestamps unless a
     user-defined conflict handler overrides this.
    </para>

    <para>
     No special administrator action is required to deal with these conflicts,
     but the user must understand that <emphasis>one of the
     <literal>INSERT</literal>ed tuples is effectively discarded on all
     nodes</emphasis> - there is no data merging done unless a user defined
     conflict handler does it.
    </para>

    <para>
     Conflict handling is only possible when <emphasis>only one constraint
     is violated by the incoming insert from the remote node</emphasis>;
     <xref linkend="conflicts-insert-unique-multiple-index"> are more
     problematic.
    </para>

   </sect3>

   <sect3 id="conflicts-insert-unique-multiple-index"
         xreflabel="INSERTs that violate multiple UNIQUE constraints">

    <title>INSERTs that violate multiple UNIQUE constraints</title>

    <indexterm><primary>limitations</primary></indexterm>
    <indexterm><primary>divergence</primary></indexterm>

    <para>
     An <literal>INSERT</literal>/<literal>INSERT</literal> conflict
     can violate more than one <literal>UNIQUE</literal> constraint
     (of which one might be the <literal>PRIMARY KEY</literal>).
    </para>

    <para>
     &bdr; can only handle an
     <literal>INSERT</literal>/<literal>INSERT</literal> conflict on one
     unique constraint (including the <literal>PRIMARY KEY</literal>). If a
     new row conflicts with more than one <literal>UNIQUE</literal> constraint
     then the apply worker that's trying to apply the change will
     <literal>ERROR</literal> out with:
     <programlisting>
     ERROR: multiple unique constraints violated by remotely INSERTed tuple
     </programlisting>
     (Older versions would report a <literal>"diverging uniqueness
     conflict"</literal> error instead).
    </para>

    <para>
     In case of such a conflict, you must manually remove the conflicting
     tuple(s) from the local side by <literal>DELETE</literal>ing it or by
     <literal>UPDATE</literal>ing it so that it no longer conflicts with the
     new remote tuple. There may be more than one conflicting tuple. There is
     not currently any built-in facility to ignore, discard or merge tuples
     that violate more than one local unique constraint.
    </para>

    <para>
     See also: <xref linkend="conflicts-update-unique-multiple-index">
    </para>

   </sect3>

   <sect3 id="conflicts-update-update" xreflabel="UPDATE/UPDATE conflicts">
    <title>UPDATE/UPDATE conflicts</title>

    <para>
     Where two concurrent <literal>UPDATE</literal>s on different nodes change
     the same tuple (but not its <literal>PRIMARY KEY</literal>), an
     <literal>UPDATE</literal>/<literal>UPDATE</literal> conflict occurs on
     replay. These are resolved using last-update-wins handling or, if it
     exists, a user-defined conflict handler.
    </para>

    <para>
     Because a <literal>PRIMARY KEY</literal> must exist in order to match tuples
     and perform conflict resolution, <literal>UPDATE</literal>s are rejected
     on tables without a <literal>PRIMARY KEY</literal> with:
     <programlisting>
      ERROR: Cannot run UPDATE or DELETE on table (tablename) because it does not have a primary key.
     </programlisting>
    </para>

   </sect3>

   <sect3 id="conflicts-update-pk" xreflabel="UPDATE conflicts on the PRIMARY KEY">
    <title>UPDATE conflicts on the PRIMARY KEY</title>

    <indexterm><primary>limitations</primary></indexterm>
    <indexterm><primary>divergence</primary></indexterm>

    <para>
     &bdr; cannot currently perform last-update-wins conflict resolution where
     the <literal>PRIMARY KEY</literal> is changed by an <literal>UPDATE</literal>
     operation. It is permissible to update the primary key, but you must
     ensure that no conflict with existing values is possible.
    </para>

    <para>
     Conflicts on update of the primary key are divergent conflicts that require
     manual operator intervention; see <xref linkend="conflicts-divergent">.
    </para>

   </sect3>

   <sect3 id="conflicts-update-unique-multiple-index"
    xreflabel="UPDATEs that violate multiple UNIQUE constraints">

    <title>UPDATEs that violate multiple UNIQUE constraints</title>

    <indexterm><primary>limitations</primary></indexterm>
    <indexterm><primary>divergence</primary></indexterm>

    <para>
     Like <xref linkend="conflicts-insert-unique-multiple-index">,
     where an incoming <literal>UPDATE</literal> violates more than
     one <literal>UNIQUE</literal> index (and/or the <literal>PRIMARY
     KEY</literal>), &bdr; cannot apply last-update-wins conflict resolution.
    </para>

    <para>
     This is a divergent conflict that will require operator intervention;
     see <xref linkend="conflicts-divergent">.
    </para>

   </sect3>

   <sect3 id="conflicts-update-delete" xreflabel="UPDATE/DELETE conflicts">
    <title>UPDATE/DELETE conflicts</title>

    <para>
     It is possible for one node to <literal>UPDATE</literal> a row that
     another node simultaneously <literal>DELETE</literal>s. In this case a
     <literal>UPDATE</literal>/<literal>DELETE</literal> conflict occurs on
     replay. The resolution of this conflict is to discard any
     <literal>UPDATE</literal> that arrives after the
     <literal>DELETE</literal> unless a user-defined conflict handler specifies
     otherwise.
    </para>

    <para>
     Because a <literal>PRIMARY KEY</literal> must exist in order to match tuples
     and perform conflict resolution, <literal>DELETE</literal>s are rejected
     on tables without a <literal>PRIMARY KEY</literal> with:
     <programlisting>
      ERROR: Cannot run UPDATE or DELETE on table (tablename) because it does not have a primary key.
     </programlisting>
    </para>

    <note>
     <para>
      <indexterm><primary>limitations</primary></indexterm>
      <indexterm><primary>divergence</primary></indexterm>
      &bdr; cannot currently differentiate between
      <literal>UPDATE</literal>/<literal>DELETE</literal> conflicts and
      <xref linkend="conflicts-insert-update">. In both
      cases an <literal>UPDATE</literal> arrives that affects a nonexistent
      row. Since &bdr; is asynchronous and there's no ordering of replay
      between nodes, it can't tell if this is an update to a new row we haven't
      yet received the insert for, or a row we've already replayed a delete
      for. In both cases the resolution is the same - the update is discarded.
     </para>
    </note>

   </sect3>

   <sect3 id="conflicts-insert-update" xreflabel="INSERT/UPDATE conflicts">
    <title>INSERT/UPDATE conflicts</title>

    <para>
     If one node <literal>INSERT</literal>s a row which is then replayed
     to a 2nd node and <literal>UPDATE</literal>d there, a 3rd node may
     receive the <literal>UPDATE</literal> from the 2nd node before it receives
     the <literal>INSERT</literal> from the 1st node. This is an
     <literal>INSERT</literal>/<literal>UPDATE</literal> conflict.
    </para>

    <para>
     <indexterm><primary>limitations</primary></indexterm>
     <indexterm><primary>divergence</primary></indexterm>
     Unless a user defined conflict trigger determines otherwise these
     conflicts are handled by discarding the <literal>UPDATE</literal>.  This
     can lead to <emphasis>different data on different nodes</emphasis>. See
     <xref linkend="conflicts-update-delete"> for details.
    </para>

   </sect3>

   <sect3 id="conflicts-delete-delete" xreflabel="DELETE/DELETE conflicts">
    <title>DELETE/DELETE conflicts</title>

    <para>
     A <literal>DELETE</literal>/<literal>DELETE</literal> conflict arises
     where two different nodes concurrently delete the same tuple.
    </para>

    <para>
     This conflict is harmless since both <literal>DELETE</literal>s have
     the same effect, so one of them can be safely ignored.
    </para>

   </sect3>

  </sect2>

  <sect2 id="conflicts-foreign-key" xreflabel="Foreign key conflicts">
   <title>Foreign Key Constraint conflicts</title>

   <para>
    Conflicts between a remote transaction being applied and existing local data
    can also occur for <literal>FOREIGN KEY</literal> constraints. These
    conflicts are usually transient issues that arise from transactions being
    applied in a different order to the order they appeared to occur logically
    on the nodes that originated them.
   </para>

   <para>
    While apply is strictly ordered for any given origin node, there is no
    enforcement of ordering of transactions between two different nodes, so
    it's possible for (e.g.) node1 to insert a row into T1, which is replayed to node2.
    node2 inserts a row into T2 which has a foreign key reference to the row from T1.
    On node3, if the transaction from node2 that inserts the row into T2 is received
    <emphasis>before</emphasis> the transaction from node1 that inserts the row into T1,
    the transaction from node2 will fail to apply. This failure will record a rollback
    in <xref linkend="catalog-pg-stat-bdr"> and an <literal>ERROR</literal>
    with details in the PostgreSQL error log on the applying node (node3). In
    this case &bdr; will retry the transaction from node2 periodicially, so
    once it's replayed the transaction from node1 that it depends on the
    transaction will commit successfully.
   </para>

   <sect3 id="conflict-foreign-key-deadlock"
          xreflabel="Foreign key constraint deadlocks">
    <title>Foreign key constraint deadlocks</title>

   <para>
    <indexterm><primary>limitations</primary></indexterm>
    <indexterm><primary>divergence</primary></indexterm>
    Simple foreign key constraint conflicts are generally transient and
    require no administrator action, but for transactions that change multiple
    entities this is not always the case. It is possible for
    concurrent changes to tables with foreign key constraints to create
    <emphasis>inter-node replication deadlocks</emphasis> where no node can
    apply changes from any other node because they conflict with local data.
    This causes replication activity to stop until the deadlock is broken by a
    local data change on one or more of the nodes.
   </para>

   <para>
    For example, take a two node system with two tables and some existing data:
    <programlisting>
    CREATE TABLE parent(
     id integer primary key
    );

    CREATE TABLE child(
     id integer primary key,
     parent_id integer not null references parent(id)
    );

    INSERT INTO parent(id)
    VALUES (1), (2);

    INSERT INTO child(id, parent_id)
    VALUES (11, 1), (11, 2);
    </programlisting>
    If node A does:
    <programlisting>
    INSERT INTO child(id, parent_id)
    VALUES (21, 2);
    </programlisting>
    and <emphasis>at the same time</emphasis> node B does:
    <programlisting>
    DELETE FROM child WHERE parent_id = 2;
    DELETE FROM parent WHERE id = 2;
    </programlisting>
    then we have a situation where the transaction from node A cannot apply
    successfully to the <literal>child</literal> table on node B because the
    referenced <literal>parent</literal> no longer exists. The transaction
    from node B cannot apply to node A because it deletes a
    <literal>parent</literal> tuple that's still referenced, the new one with
    id=21. Neither transaction can replay, and both will output periodic
    <literal>ERROR</literal>s in the log files as they are retried. Since
    &bdr; replays transactions from a given node strictly in order, neither
    node can make progress with replication unless the user, or some 3rd node,
    makes changes that resolve the deadlock.
   </para>

   <para>
    It is important to note that when we manually deleted the child tuples
    on node B, the newly inserted child on node A was not affected because
    it had not yet replicated to node B. If either node replays the other's
    transaction before attempting its own local transaction then no problem
    will occur.
   </para>

   <para>
    Solving such a foreign key deadlock requires that you fix the constraint
    issue on each end. In this case, you would need to insert a dummy
    <literal>parent</literal> row on node B and delete the new child on node
    A. Replay will continue past the deadlock point.
   </para>

   <para>
    &bdr; can't just apply the changes from each end anyway because doing so
    would result in tables that violated their declared foreign key
    constraints, which most users would view as corruption.
   </para>

   </sect3>

  </sect2>

  <sect2 id="conflicts-exclusion"
         xreflabel="Exclusion constraint conflicts">
   <title>Exclusion constraint conflicts</title>

   <para>
    <indexterm><primary>limitations</primary></indexterm>
    &bdr; doesn't support exclusion constraints and restricts their creation.
   </para>

   <important>
    <para>
     If an existing stand-alone database is converted to a &bdr; database then
     all exclusion constraints should be manually dropped.
    </para>
   </important>

   <para>
    In a distributed asynchronous system it is not possible to ensure that no
    set of rows that violates the constraint exists, because all transactions
    on different nodes are fully isolated. Exclusion constraints would lead to
    replay deadlocks where replay could not progress from any node to any
    other node because of exclusion constraint violations.
   </para>

   <para>
    If you force &bdr; to create an exclusion constraint, or you don't drop
    existing ones when converting a standalone database to &bdr; you should
    expect replication to break. You can get it to progress again by
    removing or altering the local tuple(s) that an incoming remote tuple
    conflicts with so that the remote transaction can be applied.
   </para>

  </sect2>

  <sect2>
   <title>Global data conflicts</title>

   <para>
    <indexterm><primary>limitations</primary></indexterm>
    <indexterm><primary>divergence</primary></indexterm>
    Conflicts can also arise where nodes have global (PostgreSQL-system-wide)
    data, like roles, that differs. This can result in operations - mainly
    <acronym>DDL</acronym> - that can be run successfully and committed
    on one node, but then fail to apply to other nodes.
   </para>

   <para>
    For example, node1 might have a user named
    <literal>fred</literal>, but that user was not created on node2.
    &bdr; does not replicate <literal>CREATE USER</literal> (see
    <xref linkend="ddl-create-role">) so this situation can arise easily.
    If <literal>fred</literal> on node1 creates a table, it will
    be replicated with its owner set to <literal>fred</literal>.
    When the DDL command is applied to node2 the DDL will fail
    because there is no user named <literal>fred</literal>.
    This failure will emit an <literal>ERROR</literal> in the
    PostgreSQL logs on node2 and increment
    <xref linkend="catalog-pg-stat-bdr"><literal>.nr_rollbacks</literal>.
   </para>

   <para>
    Administrator intervention is required to resolve this conflict
    by creating the user <literal>fred</literal> on node2.
    (It need not have the same permissions, but must exist).
   </para>

  </sect2>

  <sect2>
   <title>Lock conflicts and deadlock aborts</title>

   <para>
    Because &bdr; apply processes operate very like normal user sessions
    they are subject to the usual rules around row and table locking. This
    can sometimes lead to &bdr; apply processes waiting on locks held
    by user transactions, or even by each other.
   </para>

   <para>
    Relevant locking includes;
    <itemizedlist>
     <listitem><simpara>explicit table-level locking (<literal>LOCK TABLE ...</literal>) by user sessions</simpara></listitem>
     <listitem><simpara>explicit row level locking (<literal>SELECT ... FOR UPDATE/FOR SHARE</literal>) by user sessions</simpara></listitem>
     <listitem><simpara>locking from foreign keys</simpara></listitem>
     <listitem><simpara>implicit locking because of row <literal>UPDATE</literal>s, <literal>INSERT</literal>s or <literal>DELETE</literal>s, either from local activity or apply from other servers</simpara></listitem>
    </itemizedlist>
   </para>

   <para>
    It is even possible for a &bdr; apply process to deadlock with a user
    transaction, where the user transaction is waiting on a lock held
    by the apply process and vice versa. Two apply processes may also
    deadlock with each other. PostgreSQL's deadlock detector will
    step in and terminate one of the problem transactions. If the &bdr; apply
    worker's process is terminated it will simply retry and generally succeed.
   </para>

   <para>
    All these issues are transient and generally require no administrator
    action. If an apply process is stuck for a long time behind a lock
    on an idle user session the administrator may choose to terminate
    the user session to get replication flowing again, but this is
    no different to a user holding a long lock that impacts another
    user session.
   </para>

   <para>
    Use of the <ulink
    url="http://www.postgresql.org/docs/current/static/runtime-config-logging.html#GUC-LOG-LOCK-WAITS">
    log_lock_waits</ulink> facility in PostgreSQL can help identify locking
    related replay stalls.
   </para>

  </sect2>

  <sect2 id="conflicts-divergent" xreflabel="Divergent conflicts">
   <title>Divergent conflicts</title>

   <indexterm><primary>divergence</primary></indexterm>

   <para>
    Divergent conflicts arise when data that should be the same on different
    nodes differs unexpectedly. Divergent conflicts should not occur, but not
    all such conflicts can be reliably prevented at time of writing.
   </para>

   <warning>
    <para>
     Changing the <literal>PRIMARY KEY</literal> of a row can lead to a
     divergent conflict if another node changes the key of the same row before
     all nodes have replayed the change. Avoid changing primary keys, or
     change them only on one designated node.
     See <xref linkend="conflicts-update-pk">.
    </para>
   </warning>

   <para>
    Divergent conflicts involving row data generally require administrator
    action to manually adjust the data on one of the nodes to be consistent
    with the other one while replication is temporarily disabled using <xref
    linkend="guc-bdr-do-not-replicate">. Such conflicts should not arise
    so long as &bdr; is used as documented and settings or functions marked
    as unsafe are avoided.
   </para>

   <para>
    The administrator must manually resolve such conflicts. Use of the
    advanced options <xref linkend="guc-bdr-do-not-replicate">,
    <xref linkend="guc-bdr-skip-ddl-replication"> and
    <xref linkend="guc-bdr-permit-unsafe-ddl-commands"> may be required depending
    on the nature of the conflict. However, careless use of these options
    can make things much worse and it isn't possible to give general
    instructions for resolving all possible kinds of conflict.
   </para>

  </sect2>

 </sect1>

 <sect1 id="conflicts-avoidance" xreflabel="Conflict avoidance">
  <title>Avoiding or tolerating conflicts</title>

  <para>
   In most cases appropriate application design can be used to avoid conflicts
   and/or the application can be made tolerant of conflicts.
  </para>

  <para>
   Conflicts can only happen if there are things happening at the same time on
   multiple nodes, so the simplest way to avoid conflicts is to only ever write
   to one node, or to only ever write to independent subsets of the database on
   each node. For example, each node might have a separate schema, and while
   they all exchange data with each other, writes are only ever performed on
   the node that "owns" a given schema.
  </para>

  <para>
   For <literal>INSERT</literal> vs <literal>INSERT</literal> conflicts, use of
   <xref linkend="global-sequences"> can completely prevent conflicts.
  </para>

  <para>
   BDR users may sometimes find it useful to perform distributed locking at the
   application level in cases where conflicts are not acceptable.
  </para>

  <para>
   The best course of action is frequently to allow conflicts to occur and
   design the application to work with &bdr;'s conflict resolution
   mechansisms to cope with the conflict. See <xref linkend="conflicts-types">.
  </para>

 </sect1>

 <sect1 id="conflicts-user-defined-handlers" xreflabel="User defined conflict handlers">
  <title>User defined conflict handlers</title>

  <para>
   &bdr; provides facilities for users to override the default last-update-wins
   data row conflict resolution strategy on row key conflicts.
  </para>

  <para>
   A user defined conflict handler, if provided, is called before default
   row conflict resolution is performed. The user defined handler may choose
   to ignore the new row and keep the original local row, to apply the new
   row, or to generate a new row (possibly merging old and new) and apply
   that instead of the new incoming row. A conflict handler may also
   choose to <literal>ERROR</literal> out, which can be useful if it wishes
   to abort apply of a transaction and retry it later.
  </para>

  <para>
   Conflict handlers cannot skip whole transactions.
  </para>

  <note>
   <para>
    User-defined conflict handlers do not have access to both the old and new
    versions of the remote row, so they cannot tell which field(s) in the
    remote incoming tuple changed. It is thus not possible to do reliable row
    merging. Attempts to so for the general case will usually prove to be
    incorrect in an asynchronous replication envirionment. It's possible in
    some application-specific situations where the app "knows" more about
    the data.
   </para>
  </note>

  <!-- TODO -->

  <para>
   See also: <xref linkend="functions-conflict-handlers">
  </para>

 </sect1>

 <sect1 id="conflicts-logging" xreflabel="Conflict logging">
  <title>Conflict logging</title>

  <para>
   To make diagnosis and handling of multi-master conflicts easier, &bdr;
   supports logging of each conflict incident in a <xref linkend="catalog-bdr-conflict-history"> table.
  </para>

  <para>
   Conflict logging to this table is only enabled when <xref
   linkend="guc-bdr-log-conflicts-to-table"> is
   <literal>true</literal>. BDR also logs conflicts to the PostgreSQL
   log file if <literal>log_min_messages</literal> is <literal>LOG</literal>
   or lower, irrespective of the value of <literal>bdr.log_conflicts_to_table</literal>.
  </para>

  <para>
   You can use the conflict history table to determine how rapidly your
   application creates conflicts and where those conflicts occur, allowing you to
   improve the application to reduce conflict rates. It also helps detect cases
   where conflict resolutions may not have produced the desired results, allowing
   you to identify places where a user defined conflict trigger or an application
   design change may be desirable.
  </para>

  <para>
   Row values may optionally be logged for row conflicts. This is controlled by
   the global database-wide option <xref linkend="guc-bdr-log-conflicts-to-table">.
   There is no per-table control over row value logging at this time. Nor is
   there any limit applied on the number of fields a row may have, number of
   elements dumped in arrays, length of fields, etc, so it may not be wise to
   enable this if you regularly work with multi-megabyte rows that may trigger
   conflicts.
  </para>

  <para>
   Because the conflict history table contains data on every table in the
   database so each row's schema might be different, if row values are logged
   they are stored as json fields. The json is created with
   <function>row_to_json</function>, just like if you'd called it on the row
   yourself from SQL. There is no corresponding
   <function>json_to_row</function> function in PostgreSQL at this time, so
   you'll need table-specific code (pl/pgsql, pl/python, pl/perl, whatever) if
   you want to reconstruct a composite-typed tuple from the logged json.
  </para>

 </sect1>

</chapter>
