<chapter id="global-sequences" xreflabel="Global sequences">
 <title>Global Sequences</title>
 <indexterm>
  <primary>Global Sequence</primary>
  <secondary>Distributed sequence</secondary>
 </indexterm>

 <para>
  BDR global sequences provide an easy way for applications to use the
  database to generate unique synthetic keys in an asynchronous distributed
  system.
 </para>

 <important>
  <para>
   This chapter refers to the global sequences implementation in BDR 2.0 and
   newer. See the BDR 1.0 documentation and the upgrade guide for details on
   the quite different global sequences implementation in BDR 1.0.
  </para>
 </important>

 <warning>
  <para>
   Object-relational mappers and applications that hardcode calls to the
   <literal>nextval</> function may require special configuration to work with
   BDR 2.0 global sequences.
  </para>
 </warning>

 <sect1 id="global-sequences-purpose" xreflabel="Purpose of global sequences">
  <title>Purpose of global sequences</title>

  <para>
   Many applications require unique values be assigned to database entries. Some
   applications use <application>UUID</application>s/<application>GUID</application>s generated by external
   programs, some use database-supplied values. This is important with
   optimistic conflict resolution schemes (like that in BDR) because
   uniqueness violations can result in discarded inserts during conflict
   resolution.
  </para>

  <para>
   The SQL standard requires <literal>SEQUENCE</literal> objects which generate
   unique values.  These can then be used to supply default values using
   <literal>DEFAULT nextval('mysequence')</literal>, as with PostgreSQL's
   <literal>SERIAL</literal> pseudo-type. PostgreSQL doesn't provide
   any facilities to synchronise or replicate sequences, so they're purely
   node-local.
  </para>

  <para>
   A typical approach for sharded or multi-node applications is to use
   split-step or partitioned sequences, where all nodes increment the sequence
   by the same fixed value and each node has a fixed offset within the sequence.
   So node 1 generates IDs 1, 101, 201, 301, ...; node 2 generates IDs 2, 102,
   202, 302, ...; etc. This is easily done with PostgreSQL's existing sequences,
   but becomes a major problem if you don't allow enough room for growth - in
   the above, if you have 101 nodes you're in serious trouble. It's also
   awkward, requiring node-specific DDL and setup. It also makes replacing
   failed nodes difficult as each table must be scanned to determine what ID
   each sequence was up to on the node before failure, or a new (very finite)
   node ID must be allocated. See <xref
   linkend="global-sequences-alternatives">.
  </para>

  <para>
   To help avoid <xref linkend="conflicts"> on concurrent inserts BDR
   provides a global sequence mapping function. This allows a normal sequence
   to be used in a globally-unique manner by qualifying its result with a
   unique node ID and timestamp. See <xref linkend="global-sequence-usage">.
  </para>

  <para>
   BDR manages the node IDs internally (see <link
   linkend="catalog-bdr-nodes">the <literal>bdr.bdr_nodes.node_seq_id</>
   column</>). Node IDs for parted nodes are re-used, so node ID exhaustion
   is not a concern for environments that regularly part and join nodes, such
   as for load balancing.
  </para>

  <note>
   <para>
    BDR 1.0 provided a different implementation of global sequences which
    intercepted <function>nextval</function> requests and negotiated between
    nodes to ensure that values were unique across the whole BDR group. They
    were created with the syntax
    <literal>CREATE SEQUENCE ... USING bdr</literal>
    and used with <literal>nextval(...)</literal> like any other
    sequence. This relied on modifications to Postgres-BDR 9.4 that were not
    included in PostgreSQL 9.6 so the feature is not available on 9.6. It also
    tolerated extended network partitions poorly. New applications should avoid
    using them.
   </para>
   <para>
    The old implementation is retained for applications migrating from BDR 1.0
    that are still on BDR-Postgres 9.4. For details on the old global sequences
    implementation see the BDR 1.0 manual.
   </para>
  </para>

 </sect1>

 <sect1 id="global-sequences-when" xreflabel="When to use global sequences">
  <title>When to use global sequences</title>

  <para>
   Using global sequences allows you to avoid the problems with insert
   conflicts. If you define a <literal>PRIMARY KEY</literal> or
   <literal>UNIQUE</literal> column with a <literal>DEFAULT
   bdr.global_seq_nextval(...)</literal> expression, it is not possible for any
   node to ever get the same value as any other node. When BDR synchronizes
   inserts between the nodes, they can never conflict.
  </para>

  <para>
   There is no need to use a distributed sequence if:
   <itemizedlist>
    <listitem>
     <para>
      You are ensuring global uniqueness using another method such as:
      <itemizedlist>
       <listitem><simpara>Local sequences with an offset and increment;</simpara></listitem>
       <listitem><simpara>UUIDs;</simpara></listitem>
       <listitem><simpara>An externally co-ordinated natural key</simpara></listitem>
      </itemizedlist>
     </para>
    </listitem>
    <listitem>
     <para>
      You are using the data in a <literal>TEMPORARY</literal> or
      <literal>UNLOGGED</literal> table, as these are never visible outside the
      current node.
     </para>
    </listitem>
   </itemizedlist>
  </para>

  <para>
   Global sequences are not suitable for applications that require an
   <literal>INCREMENT</literal> other than 1. See
   <xref linkend="global-sequence-limitations">.
  </para>

  <para>
   Global sequence values are only loosely time-ordered. It is normal for one
   node to be able to generate a value lower than an earlier value generated by
   another node. This will only happen if the two nodes generated IDs within
   the same millisecond, so in practice it's not a big concern.  It does mean
   that applications that require generated IDs to strictly increase with time
   will not work well with global sequences - however, such applications will
   also have problems with all other approaches to generating keys in
   distributed systems (see <xref linkend="global-sequences-alternatives">).
   Strictly apps that need exact sequence ordering are also buggy even when run
   on a standalone PostgreSQL install, since there is no guarantee that
   transactions commit in the same order they called nextval, so "newer" IDs
   may become visible before older ones.
  </para>

  <para>
   Applications that directly call <literal>nextval</>, like many ORMs,
   will require changes to work with BDR 2.0 global sequences.
  </para>

 </sect1>

 <sect1 id="global-sequence-usage" xreflabel="Using global sequences">
  <title>Using global sequences</title>

  <para>
   To use a global sequence, create a local sequence with <literal>CREATE
   SEQUENCE ...</literal> like normal. Then instead of using
   <function>nextval(seqname)</function> to get values from it, use
   <function>bdr.global_seq_nextval(seqname)</function>. The destination
   column must be <type>BIGINT</type> as the result is 64 bits wide.
  </para>

  <para>
   If you normally create the sequence as a <type>SERIAL</type> or
   <type>BIGSERIAL</type> column you may continue to do so. To enable global sequence
   use on the column you must <literal>ALTER</literal> the <literal>DEFAULT</literal>
   expression after table creation. There is currently no facility to do this
   automatically and transparently so you need to do it in a follow up command
   like:
   <programlisting>
    ALTER TABLE my_table ALTER COLUMN my_bigserial DEFAULT bdr.global_seq_nextval('my_table_my_bigserial_seq');
   </programlisting>
  </para>

  <note>
   <para>
    Do not add a <type>SERIAL</type> or <type>BIGSERIAL</type> column to an
    existing non-empty table. Instead follow the advice for adding columns in
    the <xref linkend="ddl-replication"> chapter.
   </para>
  </note>

  <para>
   Global sequences are handled normally by <application>pg_dump</>. No special action
   is required.
  </para>

  <para>
   Global sequences work on one or more nodes and do not require any inter-node
   communication after the node join process completes. So they may continue to
   be used even if there's the risk of extended network partitions and are not
   affected by replication lag or inter-node latency.
  </para>

  <para>
   It's preferable to avoid calling <literal>nextval</literal> on a sequence
   that's used with <function>bdr.global_seq_nextval</function>. Doing so won't
   cause any harm so long as the application doesn't try to mix the results of
   the two functions in the same column and expect them to be unique.
  </para>

 </sect1>

 <sect1 id="global-sequence-limitations" xreflabel="Global Sequence Limitations">
  <title>Global sequence limitations</title>

  <para>
   A few limitations and caveats apply to global sequences at time of writing,
   in addition to those discussed in <link linkend="global-sequences-when">when
   to use global sequences</link>:
  </para>

  <para>
   There is no transparent remapping of local sequences to global sequences.
   Schemas and/or applications must be modified to explicitly call
   <function>bdr.global_seq_nextval(...)</function> or use it as a
   <literal>DEFAULT</> for a column. (A future version may handle
   <type>BIGSERIAL</> automatically).
  </para>

  <para>
   Global sequences are 64-bits wide and need a <type>bigint</> or
   <type>bigserial</>. There is no 32-bit <type>integer</> version.
   Down-casting will not work.
  </para>

  <para>
   <function>currval(...)</function> and <function>lastval()</function> return
   the value of the underlying sequence, not the value generated by
   <function>bdr.global_seq_nextval(...)</>. Do not use them with global
   sequences. This is a particular concern with <acronym>ORM</>s; see
   <xref linkend="global-sequences-orms">.
  </para>

  <para>
   The <literal>INCREMENT</> option on a sequence used as input for global
   sequences is effectively ignored. This could be relevant for applications
   that do sequence ID caching, like many object-relational mapper
   (<acronym>ORM</>) tools, notably Hibernate. Because the sequence is
   time-based this has little practical effect since the sequence will have
   advanced to a new non-colliding value by the time the application can do
   anything with the cached values.
  </para>

  <para>
   There is a limit of 8192 sequence values generated per millisecond on any
   given node for any given sequence. If more than 8192 sequences per
   millisecond are generated from one sequence on one node, the generated
   values will wrap around and collide. This will usually result in a
   <literal>UNIQUE</> constraint violation on <literal>INSERT</> or
   <literal>UPDATE</literal>. It cannot cause a replication conflict because
   sequence values generated on different nodes can <emphasis>never</> collide.
  </para>

  <para>
   In practice this is harmless since values are not generated fast enough
   to trigger this limitation. Generating a single ID typically takes over 3ns,
   so 8192 per ms is exceedingly unlikely especially since there will be other
   work being done, rows inserted, indexes updated, etc. Despite that,
   applications should have a <litreal>UNIQUE</> constraint in place where they
   absolutely rely on lack of collisions.
  </para>

  <para>
   Similarly, the <literal>MINVALUE</>, <literal>MAXVALUE</> and
   <literal>CACHE</> settings may be changed on the underlying sequence, but
   there is no benefit to doing so. The sequence's low 14 bits are used and the
   rest is discarded, so the value range limits don't affect the function's
   result. For the same reason, <function>setval(...)</> is not useful for
   sequences used with <function>bdr.global_sequence_nextval(..)</>.
  </para>

  <para>
   The <literal>CACHE</literal> directive may be used as normal. Because the
   sequence is time-based there's no point trying to avoid "unnecessary"
   sequence increments, though.
  </para>

 </sect1>

 <sect1 id="global-sequences-orms" xreflabel="Global sequences and ORMs">
  <title>Global sequences and ORMs</>

  <para>
   Some applications and <acronym>ORM</> (Object-Relational Mapper) tools
   expect to call <literal>nextval</> on a sequence directly, rather than using
   the table's declared <literal>DEFAULT</> for a column. If such an ORM is
   configured to recognise a sequence default for a column (like
   JPA/Hibernate's <literal>@SequenceGenerator</>) or auto-detects it (like
   Rails/ActiveRecord's default <literal>id</> magic) and assumes that it can
   get new values with <literal>nextval(...)</> without checking the table's
   actual <literal>DEFAULT</>, it will produce values using the underlying
   sequence not the BDR global sequence. This will very likely result in
   conflicts.
  </para>

  <para>
   Application developers should configure these tools to fetch the
   database-generated default instead of using a sequence cache, or to call
   the correct <function>bdr.global_seq_nextval</> function to generate a
   value. The application may not assume a block of IDs has been generated, as
   if an increment was set, and may only use the actual value returned.
  </para>
   
  <para>
   Alternately, the DBA may choose to create a new schema (say
   <literal>bdr_seq</>), add wrapper functions for
   <literal>nextval(regclass)</> and <literal>nextval(text)</> there that call
   <literal>bdr.global_seq_nextva(regclass)</>, and ensure that the
   application's <literal>search_path</> puts the new schema
   <literal>bdr_seq</> <emphasis>before</> <literal>pg_catalog</>.
  </para>
 </sect1>

 <sect1 id="global-sequence-voting" xreflabel="Global Sequence Voting">
  <title>Global sequence voting</title>

  <para>
   BDR 2.0 global sequences do not need to perform inter-node voting
   once the node has joined the group. They are entirely independent
   on each node and are unaffected by network partitions.
  </para>

 </sect1>

 <sect1 id="global-sequences-alternatives">
  <title>Traditional approaches to sequences in distributed DBs</title>

  <para>
   Global sequences provide a mostly-application-transparent alternative to
   using offset-step sequences or
   <acronym>UUID</acronym>/<acronym>GUID</acronym> keys, but they are not
   without downsides.
  </para>

  <para>
   BDR users may use any other multimaster-safe sequence/key generation
   strategy. It is not necessary to use global sequences. The approaches
   described below will be superior for many applications' needs, and
   more sophisticated approaches also exist.
  </para>

  <warning>
   <para>
    Applications can <emphasis>not</emphasis> safely use counter-table based
    approaches relying on <literal>SELECT ... FOR UPDATE</>, <literal>UPDATE
    ... RETURNING ...</> etc for sequence generation in BDR. Because BDR is
    asynchronous and doesn't take row locks between nodes, the same values will
    be generated on more than one node. For the same reason the usual
    strategies for "gapless" sequence generation do not work with BDR. In most
    cases the application should coordinate generation of sequences that must
    be gapless from some external source using two-phase commit, or it should
    only generate them on one node in the BDR group.
   </para>
  </warning>

  <sect2 id="global-sequences-alternative-stepoffset" xreflabel="Step/Offset sequences">
   <title>Step/offset sequences</title>

   <para>
    In offset-step sequences a normal PostgreSQL sequence is used on each node.
    Each sequence increments by the same amount and starts at differing offsets.
    For example with step 1000 node1's sequence generates 1001, 2001, 3001, and
    so on, node 2's generates 1002, 2002, 3002, etc. This scheme works well
    even if the nodes cannot communicate for extended periods, but requires
    that the designer specify a maximum number of nodes when establishing the
    schema and requires per-node configuration. Mistakes can easily lead to
    overlapping sequences.
   </para>

   <para>
    It is relatively simple to configure this approach with BDR by creating the
    desired sequence on one node like
    <programlisting>
      CREATE TABLE some_table (
        generated_value bigint primary key
      );

      CREATE SEQUENCE some_seq INCREMENT 1000 OWNED BY some_table.generated_value USING local;

      ALTER TABLE some_table ALTER COLUMN generated_value DEFAULT nextval('some_seq');
    </programlisting>
    ... then on each node calling <function>setval</function> to give each node a
    different offset starting value, e.g.
    <programlisting>
      -- On node 1
      SELECT setval('some_seq', 1);

      -- On node 2
      SELECT setval('some_seq', 2);

      -- ... etc
  </programlisting>
    You should be sure to allow a large enough <literal>INCREMENT</literal> to
    leave room for all the nodes you may ever want to add since changing it in
    future is difficult and disruptive.
   </para>

   <para>
    If you use bigint values there is no practial concern about key exhaustion
    even if you use offsets of 10000 or more. You'll need hundreds of years
    with hundreds of machines doing millions of inserts per second to have any
    chance of approaching exhaustion.
   </para>

   <para>
    BDR does not currently offer any automation for configuration of the
    per-node offsets on such step/offset sequences.
   </para>

  </sect2>

  <sect2 id="global-sequences-alternative-composite" xreflabel="Composite keys">
   <title>Composite keys</title>

   <para>
    A variant on step/offset sequences is to use a composite key composed of
    <literal>PRIMARY KEY (node_number, generated_value)</literal> where the
    node number is usually obtained from a function that returns a different
    number on each node. Such a function may be created by temporarily
    disabling DDL replication and creating a constant SQL function, or by using
    a one-row table that isn't part of a replication set to store a different
    value in each node.
   </para>
  </sect2>

  <sect2 id="global-sequences-alternative-uuid" xreflabel="UUIDs">
   <title>UUIDs</title>

   <para>
    <acronym>UUID</acronym> keys instead eschew sequences entirely and
    use 128-bit universal unique identifiers. These are large random
    or pseudorandom values that are large enough that it's nearly
    impossible for the same value to be generated twice. There is
    no need for nodes to have continuous communication when using
    <acronym>UUID</acronym> keys.
   </para>

   <para>
    In the incredibly unlikely event of a collision, conflict detection will
    choose the newer of the two inserted records to retain. Conflict logging,
    if enabled, will record such an event, but it is
    <emphasis>exceptionally</emphasis> unlikely to ever occur, since collisions
    only become practically likely after about 2^64 keys have been generated.
   </para>

   <para>
    The main downside
    of <acronym>UUID</acronym> keys is that they're somewhat space- and
    network-inefficient, consuming more space not only as a primary key, but
    also where referenced in foreign keys and when transmitted on the wire.
    Additionally, not all applications cope well with
    <application>UUID</application> keys.
   </para>

   <para>
    PostgreSQL has a built-in <literal>uuid</literal> data type and the
    <literal>uuid-ossp</literal> extension will generate UUIDs, e.g.
    <programlisting>
     CREATE EXTENSION "uuid-ossp";

     SELECT uuid_generate_v4();
    </programlisting>
   </para>
  </sect2>

 </sect1>

</chapter>
